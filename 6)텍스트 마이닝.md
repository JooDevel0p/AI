## * 텍스트 마이닝 : 비정형 데이터에 대한 마이닝 과정인데 마이닝이란 데이터로부터 통계적인 의미가 있는 개념이나 특성을 추출하고 이것들 간의 패턴이나 추세 등의 정보를 끌어내는 과정이다.   여기서 비정형 데이터란 대표적으로 인터넷에 있는 다양한 게시물이나 비정형 문서, 카카오톡 메시지 및 유튜브 동영상 등이 있다.

## * 워드 클라우드 : 텍스트 마이닝 방법 중 하나로 , 문서의 키워드, 개념 등을 직관적으로 파악할 수 있도록 핵심 단어를 시각적으로 돋보이게 하는 기법
------------
###  워드 클라우드 만들기 -> '이화여대' 검색하고 뉴스들의 제목과 내용으로 워드 클라우드 만들기


#### >메인 검색창에 '이화여대' 검색하고 뉴스 메뉴 들어가기


<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FK2kQ7%2FbtraCRS1sPV%2FwprIC9Ek6lCTQhnFCkX2b0%2Fimg.png" width="500px" height="650px" ></img>

#### >검색한 페이지 url 가져오기

```
import requests
from bs4 import BeautifulSoup

url=requests.get("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1")
html=BeautifulSoup(url.text)
```


#### >가져오고자 하는 내용이 담긴 부분 보기
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbxA2N8%2FbtraBd969to%2FKQt3adYabmh82HCSkekoAK%2Fimg.png" width="500px" height="650px" ></img>

##### -ul의 클래스가 list_news

#### >기사 하나 하나의 부분과 소스코드들 보기
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeCN8Vz%2FbtrastTWO3L%2FZ6SlZwpyBQCBXLGgYafKfk%2Fimg.png" width="400px" height="200px" ></img>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb9enEm%2FbtraqRHxoH0%2FNkYjW12CvdQOFESBJqhTB0%2Fimg.png" width="400px" height="200px" ></img>


#### >기사 하나 하나 데이터 저장하고 출력하기
```
import requests
from bs4 import BeautifulSoup

url=requests.get("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1")
html=BeautifulSoup(url.text)

for i in html.select('ul.list_news')[0].select('li.bx'):
  print(i)
  ```
  
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjzExo%2FbtraoaNRiHU%2FvgK7bNjye7hjOacm3nz6n1%2Fimg.png" width="700px" height="100px" ></img>


#### >제목 데이터 가져오기
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdXPneY%2Fbtrat3AHRLY%2FyUbIJoZ566kKOo9KD7AKr0%2Fimg.png" width="400px" height="70px" ></img>

```
import requests
from bs4 import BeautifulSoup

url=requests.get("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1")
html=BeautifulSoup(url.text)

for i in html.select('ul.list_news')[0].select('li.bx'):
  print(i.select('a.news_tit')[0].text)
  ```
  <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp23fD%2FbtraptsFtWT%2FU9RhXaP1kU6abgHPMvKBak%2Fimg.png" width="400px" height="200px" ></img>


#### >내용 가져오기

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUHMuT%2FbtrapsUMfFz%2FwVoedq9CbXM6WCklPUBaK0%2Fimg.png" width="400px" height="80px" ></img>

```
import requests
from bs4 import BeautifulSoup

url=requests.get("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1")
html=BeautifulSoup(url.text)


for i in html.select('ul.list_news')[0].select('li.bx'):
  title=i.select('a.news_tit')[0].text           #제목은 title변수에, 내용은 content 변수에 저장
  content=i.select('div.news_dsc')[0].text
  print(content)
  ```
  
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCpF8i%2FbtrasuZBP9g%2FUXRq6UdNXLakhpf5aEzWEk%2Fimg.png" width="400px" height="200px" ></img>
  

#### >제목과 내용을 하나의 변수에 저장하기
```
import requests
from bs4 import BeautifulSoup

url=requests.get("https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1")
html=BeautifulSoup(url.text)

total_text=''


for i in html.select('ul.list_news')[0].select('li.bx'):
  title=i.select('a.news_tit')[0].text
  content=i.select('div.news_dsc')[0].text
  total_text+=(title + ' '+ content)

total_text
```
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc9GQoN%2Fbtrax7vLqEZ%2FlvV2DHEYmS6XJgjk6LFjy0%2Fimg.png" width="400px" height="70px" ></img>


#### >페이지 별로 url 비교해보기

1페이지 url: https://search.naver.com/search.naverwhere=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=1
 

2페이지 url:

https://search.naver.com/search.naverwhere=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=128&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=11
 

3페이지 url:

https://search.naver.com/search.naverwhere=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=148&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=21

##### -페이지 넘어가면서 start 값이 10씩 늘어나는 것을 알 수 있다.


#### >모든 페이지의 제목과 내용 저장하기

```
import requests
from bs4 import BeautifulSoup
import re
from tqdm import tqdm

total_text=''

for n in tqdm(range(1,3992,10)):    #page는 400page까지 밖에 없다.
  url=requests.get(f"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%9D%B4%ED%99%94%EC%97%AC%EB%8C%80&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start={n}")
  html=BeautifulSoup(url.text)


  for i in html.select('ul.list_news')[0].select('li.bx'):
    title=i.select('a.news_tit')[0].text
    content=i.select('div.news_dsc')[0].text
    total_text+=(title+''+content)
  ```
    

#### >전체 데이터 길이 확인해보기
```
>len(total_text)

618442
```

#### >모든 단어 빈도수 저장하기
```
>from wordcloud import WordCloud
>import matplotlib.pyplot as plt
>
>dic={}
>
>
>for i in re.findall('[가-힣]+', total_text):
>  if len(i)>2:
>    if i not in dic:
>      dic[i]=1
>    else:
>      dic[i]+=1
>
>dic

{'이화여대': 4933,
 '이공계': 23,
 '키우고': 2,
 '넘겠다': 2,
 '이화인': 38,
 '자부심을': 2,
 '되찾겠습니다': 1,
 '한국경제신문과의': 1,
 '인터뷰에': 1,
 '카디건을': 1,
 '나타난': 2,
 '김은미': 310,
.......생략.......
 '생명과학과': 27,
 '김완규': 9,
 '설립한': 19,
 '카이팜이': 4,
 '중소벤처기업부': 4,
 '대강당': 5,
 '모의논술고사를': 14,
 '실시한다': 14,
 '기간은': 10,
 '시부터': 30,
 '시까지로': 4,
 '인터넷을': 5,
 '전자상거래법': 10,
 '개정안': 7,
 '플랫폼': 148,
 '규모에': 6,
 '적용해야': 3,
 ...}
```

#### >워드 클라우드 그리기

```
wc=WordCloud(font_path='BMDOHYEON_ttf.ttf',               #폰트설정,배경 설정, 크기설정
             background_color='white',
             width=800,
             height=800).generate_from_frequencies(dic)  #빈도순으로 워드클라우드를 그린다.

plt.figure(figsize=(10,10))  #도화지 크기는 10,10 정사각형으로 그리기
plt.imshow(wc)               #wordcloud로 그려내기
plt.tight_layout()           #레이아웃에 딱 맞기 그리기
plt.axis('off')              #x,y축 없애기
plt.show()
```


<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWUD0e%2FbtraBegRYfT%2FkvXykhiWksCrssvlebEY3k%2Fimg.png" width="400px" height="400px" ></img>



